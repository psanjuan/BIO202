---
layout: topic
title: "Ordination approach to spatial analysis"
author: Jes & Sandra
output: html_document
---

**Assigned Reading:**

> Chapter 7 from: Borcard, D., Gillet, F. and Legendre, P. 2011. *Numerical Ecology with R.* Springer. [link](https://link.springer.com/book/10.1007/978-1-4419-7976-6)


```{r include = FALSE}
# This code block sets up the r session when the page is rendered to html
# include = FALSE means that it will not be included in the html document

# Write every code block to the html document 
knitr::opts_chunk$set(echo = TRUE)

# Write the results of every code block to the html document 
knitr::opts_chunk$set(eval = TRUE)

# Define the directory where images generated by knit will be saved
knitr::opts_chunk$set(fig.path = "images/08-C/")

# Set the web address where R will look for files from this repository
# Do not change this address
repo_url <- "https://raw.githubusercontent.com/fukamilab/BIO202/master/"
```

### Key Points

Two ordination-based approaches to modeling spatial structure:

1. Do an ordination of the spatial relationships among sampling locations and use these "spatial eigenvectors" to explore variation in a response variable (e.g. PCNM, MEM).
2. Do an ordination of the response (e.g. community data) and use the variogram of the resulting eigenvectors to explore spatial dependence of the primary axes of variation (e.g. MSO).

#### Approach 1: Moran's Eigenvector Maps (MEM) and Principal Coordinates of Neighbor Matrices (PCNM)

1. Construct spatial variables (eigenvectors) derived from the adjacency of sampling sites.

  + PCNM: uses a distance matrix
      1. Create a matrix of Euclidean distances among sites and set sites that are far apart to 0. (All sites must be connected.)
      2. Compute a PCoA of the distance matrix to create spatial eigenvectors representing the broadest to smallest potential spatial structures that can be detected by your sampling design.
      
  + MEM: uses similarity matrix
      1. Define a spatial weights matrix in which weights ($w_{i,j}$) are larger between sites that are more similar (e.g. closer together). 
      
      $$W[i,j] = \begin{cases}
    0 & \text{if $i$ and $j$ are not connected} \\
    w_{i,j} & \text{if $i$ and $j$ are connected}
  \end{cases}$$
  
      Note: How $W$ is defined can have a strong effect on results, so if you don't have a strong biologically motivated way to construct $W$ be sure to do some sensitivity analyses and determine which way of defining $W$ is best. The `spdep` packages has many ways to define connectivity and neighbor matrices (some examples: Delaunay triangulation, $k$-nearest neighbors, minimum spanning tree, neighbors within $d$ distance)

      2. Compute a PCoA without the square root standardization to create spatial eigenvectors from the most positively autocorrelated to the most negatively autocorrelated.

2. Test spatial eigenvectors for significant autocorrelation using Moran's I (see below).
3. Model $Y \sim \text{spatial eigenvectors}$ using linear models or canonical ordination to determine the scales at which $Y$ has spatial structure. Some propose using spatial eigenvectors to "control" for spatial autocorrelation (what do you think?), but different authors find that this may work well or poorly.

#### Approach 2: Multiscale Ordination (MSO)

1. Conduct a canonical ordination (RDA) that partitions $Y$ into fitted values explained by the covariates and residual values not explained by covariates.
2. Calculate a variogram matrix of the fitted values that shows how the fitted values covary across sites for each distance class. Plot the empirical variogram of this matrix to see the spatial structure of fitted values (e.g. spatial structure related to covariates).
3. Calculate a variogram matrix of the residual values that shows how residuals covary across sites for each distance class. Plot the empirical variogram of this matrix to see the spatial structure of residuals (e.g. spatial structure not related to covariates).


#### Correlograms

+ Correlograms are used to assess spatial autocorrelation at different spatial scales. 
+ Correlograms plot the correlation between observations as a function of the distance between them.
+ Several statistics are used in correlograms: Moran's I, Geary's c, and the Mantel statistic.
+ We can calculate whether data are significantly autocorrelated at a given spatial scale by comparing the observed value of a statistic to its expected value. It is usually better to use permutations to test in case normality is violated.
+ If testing multiple distance classes, p-values should be adjusted for multiple tests (e.g. Holm's or Bonferroni correction).
+ We can only test for significance if data are stationary: there is not trend in the mean or the spatial covariance across the spatial extent of the data. If there is a trend, we can try "detrending" by modeling the data as a function of the site-coordinates and then testing the residuals.


#### Other resources

A list of papers that might be useful:

+ Legendre and Gauthier 2014. Statistical methods for temporal and spaceâ€“time analysis of community composition. Proc. R. Soc. B. DOI: [10.1098/rspb.2013.2728](http://dx.doi.org/10.1098/rspb.2013.2728)

+ Wagner 2013. Rethinking the linear regression model for spatial ecological data. Ecology. DOI: [10.1890/12-1899.1](http://dx.doi.org/10.1890/12-1899.1) Describes a method called "spatial component regression".

### Analysis Example

First, let's get the data:

```{r results = 'hide'}
library(vegan)
library(adespatial)
library(ade4)
source("https://raw.githubusercontent.com/JoeyBernhardt/NumericalEcology/master/sr.value.R") 
  
# Data converted to semi-quantitative
data <- cbind(c(1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 100, 100, 30, 100, 100, 100, 100, 100, 100, 76, 3, 76, 1, 0, 75, 76, 0, 1, 0, 0, 1, 0, 0, 0, 0), c(75, 0, 0, 30, 0, 0, 0, 0, 0, 0, 0, 0, 0, 75, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 75, 1, 1, 2, 2, 0, 0, 0, 0, 100, 75, 1, 2, 0, 0, 0, 0, 0), c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 30, 0, 75, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), c(0, 75, 0, 0, 75, 1, 0, 77, 75, 75, 75, 2, 100, 2, 100, 100, 100, 30, 30, 77, 100, 100, 100, 100, 100, 100, 77, 100, 75, 77, 31, 0, 30, 76, 30, 1, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 100, 77, 2, 76, 2, 0, 100, 30, 1), c(75, 75, 100, 75, 0, 100, 100, 0, 0, 0, 0, 0, 30, 75, 0, 0, 0, 30, 30, 100, 75, 30, 75, 30, 0, 0, 75, 0, 0, 0, 30, 0, 0, 0, 75, 0, 0, 76, 100, 100, 100, 100, 100, 100, 100, 100, 77, 100, 100, 100, 100, 100, 0, 0, 0))
colnames(data) <- c("pt", "sp", "co", "ly", "fe") # clades
# vector indicating distance from river
riv.dist <- c(seq(35,1),seq(1,20))
# vector indicating point along transect
trans.dist <- seq(1,nrow(data),1)
```

#### Two naive examples, using spatial data but no autocorrelation

Now, we can do an RDA using distance from the river, or distance along the transect, as a possible explanatory variable. First, distance from the river:

```{r}
riv.rda <- rda(data,riv.dist)
summary(riv.rda)
```

The RDA explains very little of the variance. Now, we can try distance along the transect:

```{r}
trans.rda <- rda(data,trans.dist)
summary(trans.rda)
```

This is even worse.

Now, for examples from this week's reading:

#### PCNM/MEM

We will begin by looking at the locations only and calculating a PCoA based only on the distances between the locations. So we're not looking at the actual occurrence data yet, just the locations where the data were taken from.

```{r}
trans.dm <- dist(trans.dist) # create distance matrix
thresh <- 1 # truncation distance set to 1
trans.dm[trans.dm > thresh] <- 4 * thresh # truncation to threshold

# Make the PCoA
trans.pcoa <- cmdscale(trans.dm, eig=TRUE, k=54) # this is the highest possible value of k in this case, see the textbook for other possibilities

# Count the positive eigenvalues
nb.ev <- length(which(trans.pcoa$eig > 0.0000000000001))

# Matrix of PCNM variables
trans.PCNM <- as.data.frame(trans.pcoa$points[,1:nb.ev])

# Plot some of these
par(mfrow=c(3,2))
somePCNM <- c(1,2,4,8,16,37)
for(i in 1:length(somePCNM)) {
plot(trans.PCNM[,somePCNM[i]],type="l",ylab=c("PCNM",somePCNM[i]))
}

```

So, these are some of the possible autocorrleation patterns that we might expect to see in the data. We can now test these against the actual data.


```{r}
# Detrend the data
trans.dist.x <- as.data.frame(trans.dist) # need to make this a data frame in order to detrend
data.D <- dist(data)
data.det <- resid(lm(as.matrix(data.D) ~ ., data=trans.dist.x))

# Run PCNM
PCNM <- rda(data.det,trans.PCNM)
anova.cca(PCNM)

# Compute adj R2, run forward selection of variables
R2a <- RsquareAdj(PCNM)$adj.r.squared
PCNM.fwd <- forward.sel(data.det, as.matrix(trans.PCNM),adjR2thresh=R2a)
```

```{r}
# We can see the variables by viewing the object
PCNM.fwd
```

```{r}
# Make object with significant PCNMs
PCNM.sign <- sort(PCNM.fwd[,2])

# Now we can write the significant variables to a new object
PCNM.red <- trans.PCNM[,c(PCNM.sign)]

# Now re-run RDA with only significant PCNMs
PCNM2 <- rda(data.det ~ ., data=PCNM.red)

# Get new adj R2
R2a <- RsquareAdj(PCNM2)$adj.r.squared

anova.cca(PCNM2)
```

```{r}
# Number of significant axes
(axes.test <- anova.cca(PCNM2, by="axis")) # only the first 2 are significant
```

```{r}
# Now we can plot the 2 significant axes
PCNM.axes <- scores(PCNM2, choices=c(1,2), display="lc",scaling=1) # had to use "scores" instead of "scores.cca"
par(mfrow=c(2,1))
plot(trans.dist, PCNM.axes[,1]) # had to use "plot" instead of "sr.value"
plot(trans.dist, PCNM.axes[,2])
```

Finally, let's look at the summary output.

```{r}
summary(PCNM2)
```

RDA1 is our most informative axis. PC1 does explain noticeably more than RDA2, which is maybe not ideal, but there clearly is value in running the RDA.

#### Multiscale Ordination (MSO)

First, we can run a MSO using undetrended data.

```{r}
# Initial RDA with distance from river as explanatory variable
river.rda <- rda(data,riv.dist)

#Multiscale ordination
river.mso <- mso(river.rda,trans.dist,  perm=999)

#Plot
msoplot(river.mso, ylim=c(0,15000), xlim=c(-20,40))
```

Now we can run a MSO using detrended data.

```{r}
# Initial RDA with distance from river as explanatory variable
river.rda2 <- rda(data.det,riv.dist)

#Multiscale ordination
river.mso2 <- mso(river.rda2,trans.dist,  perm=999)

#Plot
msoplot(river.mso2)
```

### Discussion Questions

1) When is MEM/PCNM the most appropriate method to use, and when is MSO the most appropriate method to use?

2) Are there circumstances in which it would be inappropriate to use either of these methods?

3) In what circumstances would we find significant PCNM axes at both the broad and fine scale?

4) Can you think of any examples in which you might apply either of these methods to your data?

5) When would you want to run a MSO using undetrended data, and when would you want to use detrended data?

6) When would it be most appropriate to use MEM and when would it be most appropriate to use PCNM?